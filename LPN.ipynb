{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to C:\\Users\\zyr/.cache\\torch\\hub\\checkpoints\\resnet50-19c8e357.pth\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_view_net(\n",
      "  (model_1): ft_net_cvusa_LPN_R(\n",
      "    (model): ResNet(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (model_2): ft_net_cvusa_LPN(\n",
      "    (model): ResNet(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (3): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (4): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (5): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(8, 1))\n",
      "    (maxpool): AdaptiveMaxPool2d(output_size=(8, 1))\n",
      "  )\n",
      "  (classifier0): ClassBlock(\n",
      "    (add_block): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=701, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier1): ClassBlock(\n",
      "    (add_block): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=701, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier2): ClassBlock(\n",
      "    (add_block): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=701, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier3): ClassBlock(\n",
      "    (add_block): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=701, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier4): ClassBlock(\n",
      "    (add_block): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=701, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier5): ClassBlock(\n",
      "    (add_block): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=701, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier6): ClassBlock(\n",
      "    (add_block): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=701, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier7): ClassBlock(\n",
      "    (add_block): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=701, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "torch.Size([2, 701])\n",
      "torch.Size([2, 701])\n",
      "torch.Size([2, 701])\n",
      "torch.Size([2, 701])\n",
      "torch.Size([2, 701])\n",
      "torch.Size([2, 701])\n",
      "torch.Size([2, 701])\n",
      "torch.Size([2, 701])\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torchvision import models\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "\n",
    "######################################################################\n",
    "def weights_init_kaiming(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # print(classname)\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_in') # For old pytorch, you may use kaiming_normal.\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.kaiming_normal_(m.weight.data, a=0, mode='fan_out')\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "    elif classname.find('BatchNorm1d') != -1:\n",
    "        init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "def weights_init_classifier(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        init.normal_(m.weight.data, std=0.001)\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "def fix_relu(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('ReLU') != -1:\n",
    "        m.inplace=True\n",
    "\n",
    "# Defines the new fc layer and classification layer\n",
    "# |--Linear--|--bn--|--relu--|--Linear--|\n",
    "class ClassBlock(nn.Module):\n",
    "    def __init__(self, input_dim, class_num, droprate, relu=False, bnorm=True, num_bottleneck=512, linear=True, return_f = False):\n",
    "        super(ClassBlock, self).__init__()\n",
    "        self.return_f = return_f\n",
    "        add_block = []\n",
    "        if linear:\n",
    "            add_block += [nn.Linear(input_dim, num_bottleneck)]\n",
    "        else:\n",
    "            num_bottleneck = input_dim\n",
    "        if bnorm:\n",
    "            add_block += [nn.BatchNorm1d(num_bottleneck)]\n",
    "        if relu:\n",
    "            add_block += [nn.LeakyReLU(0.1)]\n",
    "        if droprate>0:\n",
    "            add_block += [nn.Dropout(p=droprate)]\n",
    "        add_block = nn.Sequential(*add_block)\n",
    "        add_block.apply(weights_init_kaiming)\n",
    "\n",
    "        classifier = []\n",
    "        classifier += [nn.Linear(num_bottleneck, class_num)]\n",
    "        classifier = nn.Sequential(*classifier)\n",
    "        classifier.apply(weights_init_classifier)\n",
    "\n",
    "        self.add_block = add_block\n",
    "        self.classifier = classifier\n",
    "    def forward(self, x):\n",
    "        x = self.add_block(x)\n",
    "        if self.return_f:\n",
    "            f = x\n",
    "            x = self.classifier(x)\n",
    "            return x,f\n",
    "        else:\n",
    "            x = self.classifier(x)\n",
    "            return x\n",
    "\n",
    "class ft_net_VGG16(nn.Module):\n",
    "\n",
    "    def __init__(self, class_num, droprate=0.5, stride=2, init_model=None, pool='avg'):\n",
    "        super(ft_net_VGG16, self).__init__()\n",
    "        model_ft = models.vgg16_bn(pretrained=True)\n",
    "        # avg pooling to global pooling\n",
    "        #if stride == 1:\n",
    "        #    model_ft.layer4[0].downsample[0].stride = (1,1)\n",
    "        #    model_ft.layer4[0].conv2.stride = (1,1)\n",
    "\n",
    "        self.pool = pool\n",
    "        if pool =='avg+max':\n",
    "            model_ft.avgpool2 = nn.AdaptiveAvgPool2d((1,1))\n",
    "            model_ft.maxpool2 = nn.AdaptiveMaxPool2d((1,1))\n",
    "            self.model = model_ft\n",
    "            #self.classifier = ClassBlock(4096, class_num, droprate)\n",
    "        elif pool=='avg':\n",
    "            model_ft.avgpool2 = nn.AdaptiveAvgPool2d((1,1))\n",
    "            self.model = model_ft\n",
    "            #self.classifier = ClassBlock(2048, class_num, droprate)\n",
    "        elif pool=='max':\n",
    "            model_ft.maxpool2 = nn.AdaptiveMaxPool2d((1,1))\n",
    "            self.model = model_ft\n",
    "\n",
    "        if init_model!=None:\n",
    "            self.model = init_model.model\n",
    "            self.pool = init_model.pool\n",
    "            #self.classifier.add_block = init_model.classifier.add_block\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.features(x)\n",
    "        if self.pool == 'avg+max':\n",
    "            x1 = self.model.avgpool2(x)\n",
    "            x2 = self.model.maxpool2(x)\n",
    "            x = torch.cat((x1,x2), dim = 1)\n",
    "            x = x.view(x.size(0), x.size(1))\n",
    "        elif self.pool == 'avg':\n",
    "            x = self.model.avgpool2(x)\n",
    "            x = x.view(x.size(0), x.size(1))\n",
    "        elif self.pool == 'max':\n",
    "            x = self.model.maxpool2(x)\n",
    "            x = x.view(x.size(0), x.size(1))\n",
    "\n",
    "        #x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Define the VGG16-based part Model\n",
    "class ft_net_VGG16_LPN(nn.Module):\n",
    "\n",
    "    def __init__(self, class_num, droprate=0.5, stride=2, init_model=None, pool='avg', block=8, row = False):\n",
    "        super(ft_net_VGG16_LPN, self).__init__()\n",
    "        model_ft = models.vgg16_bn(pretrained=True)\n",
    "        # avg pooling to global pooling\n",
    "        #if stride == 1:\n",
    "        #    model_ft.layer4[0].downsample[0].stride = (1,1)\n",
    "        #    model_ft.layer4[0].conv2.stride = (1,1)\n",
    "\n",
    "        self.pool = pool\n",
    "        self.model = model_ft\n",
    "        self.block = block\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,block))\n",
    "        self.maxpool = nn.AdaptiveMaxPool2d((1,block))\n",
    "        if row:  # row partition the ground view image\n",
    "            self.avgpool = nn.AdaptiveAvgPool2d((block,1))\n",
    "            self.maxpool = nn.AdaptiveMaxPool2d((block,1))\n",
    "        if init_model!=None:\n",
    "            self.model = init_model.model\n",
    "            self.pool = init_model.pool\n",
    "            #self.classifier.add_block = init_model.classifier.add_block\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.features(x)\n",
    "        # print(x.size())\n",
    "        if self.pool == 'avg+max':\n",
    "            x1 = self.avgpool(x)\n",
    "            x2 = self.maxpool(x)\n",
    "            x = torch.cat((x1,x2), dim = 1)\n",
    "            x = x.view(x.size(0), x.size(1), -1)\n",
    "        elif self.pool == 'avg':\n",
    "            x = self.avgpool(x)\n",
    "            # print(x.size())\n",
    "            x = x.view(x.size(0), x.size(1), -1)\n",
    "            # print(x)\n",
    "        elif self.pool == 'max':\n",
    "            x = self.maxpool(x, pool='max')\n",
    "            x = x.view(x.size(0), x.size(1), -1)\n",
    "        #x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Define vgg16 based square ring partition for satellite images of cvusa/cvact\n",
    "class ft_net_VGG16_LPN_R(nn.Module):\n",
    "\n",
    "    def __init__(self, class_num, droprate=0.5, stride=2, init_model=None, pool='avg', block=4):\n",
    "        super(ft_net_VGG16_LPN_R, self).__init__()\n",
    "        model_ft = models.vgg16_bn(pretrained=True)\n",
    "        # avg pooling to global pooling\n",
    "        #if stride == 1:\n",
    "        #    model_ft.layer4[0].downsample[0].stride = (1,1)\n",
    "        #    model_ft.layer4[0].conv2.stride = (1,1)\n",
    "\n",
    "        self.pool = pool\n",
    "        self.model = model_ft\n",
    "        self.block = block\n",
    "        if init_model!=None:\n",
    "            self.model = init_model.model\n",
    "            self.pool = init_model.pool\n",
    "            #self.classifier.add_block = init_model.classifier.add_block\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.features(x)\n",
    "        # print(x.size())\n",
    "        if self.pool == 'avg+max':\n",
    "            x1 = self.get_part_pool(x, pool='avg')\n",
    "            x2 = self.get_part_pool(x, pool='max')\n",
    "            x = torch.cat((x1,x2), dim = 1)\n",
    "            x = x.view(x.size(0), x.size(1), -1)\n",
    "        elif self.pool == 'avg':\n",
    "            x = self.get_part_pool(x)\n",
    "            # print(x.size())\n",
    "            x = x.view(x.size(0), x.size(1), -1)\n",
    "            # print(x)\n",
    "        elif self.pool == 'max':\n",
    "            x = self.get_part_pool(x, pool='max')\n",
    "            x = x.view(x.size(0), x.size(1), -1)\n",
    "        #x = self.classifier(x)\n",
    "        return x\n",
    "    # VGGNet's output: 8*8 part:4*4, 6*6, 8*8\n",
    "    def get_part_pool(self, x, pool='avg', no_overlap=True):\n",
    "        result = []\n",
    "        if pool == 'avg':\n",
    "            pooling = torch.nn.AdaptiveAvgPool2d((1,1))\n",
    "        elif pool == 'max':\n",
    "            pooling = torch.nn.AdaptiveMaxPool2d((1,1)) \n",
    "        H, W = x.size(2), x.size(3)\n",
    "        c_h, c_w = int(H/2), int(W/2)\n",
    "        per_h, per_w = H/(2*self.block),W/(2*self.block)\n",
    "        if per_h < 1 and per_w < 1:\n",
    "            new_H, new_W = H+(self.block-c_h)*2, W+(self.block-c_w)*2\n",
    "            x = nn.functional.interpolate(x, size=[new_H,new_W], mode='bilinear')\n",
    "            H, W = x.size(2), x.size(3)\n",
    "            c_h, c_w = int(H/2), int(W/2)\n",
    "            per_h, per_w = H/(2*self.block),W/(2*self.block)\n",
    "        per_h, per_w = math.floor(per_h), math.floor(per_w)\n",
    "        for i in range(self.block):\n",
    "            i = i + 1\n",
    "            if i < self.block:\n",
    "                x_curr = x[:,:,(c_h-i*per_h):(c_h+i*per_h),(c_w-i*per_w):(c_w+i*per_w)]\n",
    "                if no_overlap and i > 1:\n",
    "                    x_pre = x[:,:,(c_h-(i-1)*per_h):(c_h+(i-1)*per_h),(c_w-(i-1)*per_w):(c_w+(i-1)*per_w)] \n",
    "                    x_pad = F.pad(x_pre,(per_h,per_h,per_w,per_w),\"constant\",0)\n",
    "                    x_curr = x_curr - x_pad\n",
    "                avgpool = pooling(x_curr)\n",
    "                result.insert(0, avgpool)\n",
    "            else:\n",
    "                if no_overlap and i > 1:\n",
    "                    x_pre = x[:,:,(c_h-(i-1)*per_h):(c_h+(i-1)*per_h),(c_w-(i-1)*per_w):(c_w+(i-1)*per_w)]\n",
    "                    pad_h = c_h-(i-1)*per_h\n",
    "                    pad_w = c_w-(i-1)*per_w\n",
    "                    # x_pad = F.pad(x_pre,(pad_h,pad_h,pad_w,pad_w),\"constant\",0)\n",
    "                    if x_pre.size(2)+2*pad_h == H:\n",
    "                        x_pad = F.pad(x_pre,(pad_h,pad_h,pad_w,pad_w),\"constant\",0)\n",
    "                    else:\n",
    "                        ep = H - (x_pre.size(2)+2*pad_h)\n",
    "                        x_pad = F.pad(x_pre,(pad_h+ep,pad_h,pad_w+ep,pad_w),\"constant\",0)\n",
    "                    x = x - x_pad\n",
    "                avgpool = pooling(x)\n",
    "                result.insert(0, avgpool)\n",
    "        return torch.cat(result, dim=2)\n",
    "\n",
    "# resnet50 backbone\n",
    "class ft_net_cvusa_LPN(nn.Module):\n",
    "\n",
    "    def __init__(self, class_num, droprate=0.5, stride=2, init_model=None, pool='avg', block=6, row=False):\n",
    "        super(ft_net_cvusa_LPN, self).__init__()\n",
    "        model_ft = models.resnet50(pretrained=True)\n",
    "        # avg pooling to global pooling\n",
    "        if stride == 1:\n",
    "            model_ft.layer4[0].downsample[0].stride = (1,1)\n",
    "            model_ft.layer4[0].conv2.stride = (1,1)\n",
    "\n",
    "        self.pool = pool\n",
    "        self.model = model_ft\n",
    "        self.block = block\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,block))\n",
    "        self.maxpool = nn.AdaptiveMaxPool2d((1,block))\n",
    "        if row:\n",
    "            self.avgpool = nn.AdaptiveAvgPool2d((block,1))\n",
    "            self.maxpool = nn.AdaptiveMaxPool2d((block,1))\n",
    "        if init_model!=None:\n",
    "            self.model = init_model.model\n",
    "            self.pool = init_model.pool\n",
    "            #self.classifier.add_block = init_model.classifier.add_block\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.conv1(x)\n",
    "        x = self.model.bn1(x)\n",
    "        x = self.model.relu(x)\n",
    "        x = self.model.maxpool(x)\n",
    "        x = self.model.layer1(x)\n",
    "        x = self.model.layer2(x)\n",
    "        x = self.model.layer3(x)\n",
    "        x = self.model.layer4(x)\n",
    "        # print(x.size())\n",
    "        if self.pool == 'avg+max':\n",
    "            x1 = self.avgpool(x)\n",
    "            x2 = self.maxpool(x)\n",
    "            x = torch.cat((x1,x2), dim = 1)\n",
    "            x = x.view(x.size(0), x.size(1), -1)\n",
    "        elif self.pool == 'avg':\n",
    "            x = self.avgpool(x)\n",
    "            # print(x.size())\n",
    "            x = x.view(x.size(0), x.size(1), -1)\n",
    "            # print(x)\n",
    "        elif self.pool == 'max':\n",
    "            x = self.maxpool(x, pool='max')\n",
    "            x = x.view(x.size(0), x.size(1), -1)\n",
    "        #x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class ft_net_cvusa_LPN_R(nn.Module):\n",
    "\n",
    "    def __init__(self, class_num, droprate=0.5, stride=2, init_model=None, pool='avg', block=6):\n",
    "        super(ft_net_cvusa_LPN_R, self).__init__()\n",
    "        model_ft = models.resnet50(pretrained=True)\n",
    "        # avg pooling to global pooling\n",
    "        if stride == 1:\n",
    "            model_ft.layer4[0].downsample[0].stride = (1,1)\n",
    "            model_ft.layer4[0].conv2.stride = (1,1)\n",
    "\n",
    "        self.pool = pool\n",
    "        self.model = model_ft\n",
    "        self.block = block\n",
    "        if init_model!=None:\n",
    "            self.model = init_model.model\n",
    "            self.pool = init_model.pool\n",
    "            #self.classifier.add_block = init_model.classifier.add_block\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.conv1(x)\n",
    "        x = self.model.bn1(x)\n",
    "        x = self.model.relu(x)\n",
    "        x = self.model.maxpool(x)\n",
    "        x = self.model.layer1(x)\n",
    "        x = self.model.layer2(x)\n",
    "        x = self.model.layer3(x)\n",
    "        x = self.model.layer4(x)\n",
    "        # print(x.size())\n",
    "        if self.pool == 'avg+max':\n",
    "            x1 = self.get_part_pool(x, pool='avg')\n",
    "            x2 = self.get_part_pool(x, pool='max')\n",
    "            x = torch.cat((x1,x2), dim = 1)\n",
    "            x = x.view(x.size(0), x.size(1), -1)\n",
    "        elif self.pool == 'avg':\n",
    "            x = self.get_part_pool(x)\n",
    "            # print(x.size())\n",
    "            x = x.view(x.size(0), x.size(1), -1)\n",
    "            # print(x)\n",
    "        elif self.pool == 'max':\n",
    "            x = self.get_part_pool(x, pool='max')\n",
    "            x = x.view(x.size(0), x.size(1), -1)\n",
    "        #x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def get_part_pool(self, x, pool='avg', no_overlap=True):\n",
    "        result = []\n",
    "        if pool == 'avg':\n",
    "            pooling = torch.nn.AdaptiveAvgPool2d((1,1))\n",
    "        elif pool == 'max':\n",
    "            pooling = torch.nn.AdaptiveMaxPool2d((1,1)) \n",
    "        H, W = x.size(2), x.size(3)\n",
    "        c_h, c_w = int(H/2), int(W/2)\n",
    "        per_h, per_w = H/(2*self.block),W/(2*self.block)\n",
    "        if per_h < 1 and per_w < 1:\n",
    "            new_H, new_W = H+(self.block-c_h)*2, W+(self.block-c_w)*2\n",
    "            x = nn.functional.interpolate(x, size=[new_H,new_W], mode='bilinear')\n",
    "            H, W = x.size(2), x.size(3)\n",
    "            c_h, c_w = int(H/2), int(W/2)\n",
    "            per_h, per_w = H/(2*self.block),W/(2*self.block)\n",
    "        per_h, per_w = math.floor(per_h), math.floor(per_w)\n",
    "        for i in range(self.block):\n",
    "            i = i + 1\n",
    "            if i < self.block:\n",
    "                x_curr = x[:,:,(c_h-i*per_h):(c_h+i*per_h),(c_w-i*per_w):(c_w+i*per_w)]\n",
    "                if no_overlap and i > 1:\n",
    "                    x_pre = x[:,:,(c_h-(i-1)*per_h):(c_h+(i-1)*per_h),(c_w-(i-1)*per_w):(c_w+(i-1)*per_w)] \n",
    "                    x_pad = F.pad(x_pre,(per_h,per_h,per_w,per_w),\"constant\",0)\n",
    "                    x_curr = x_curr - x_pad\n",
    "                avgpool = pooling(x_curr)\n",
    "                result.insert(0, avgpool)\n",
    "            else:\n",
    "                if no_overlap and i > 1:\n",
    "                    x_pre = x[:,:,(c_h-(i-1)*per_h):(c_h+(i-1)*per_h),(c_w-(i-1)*per_w):(c_w+(i-1)*per_w)]\n",
    "                    pad_h = c_h-(i-1)*per_h\n",
    "                    pad_w = c_w-(i-1)*per_w\n",
    "                    # x_pad = F.pad(x_pre,(pad_h,pad_h,pad_w,pad_w),\"constant\",0)\n",
    "                    if x_pre.size(2)+2*pad_h == H:\n",
    "                        x_pad = F.pad(x_pre,(pad_h,pad_h,pad_w,pad_w),\"constant\",0)\n",
    "                    else:\n",
    "                        ep = H - (x_pre.size(2)+2*pad_h)\n",
    "                        x_pad = F.pad(x_pre,(pad_h+ep,pad_h,pad_w+ep,pad_w),\"constant\",0)\n",
    "                    x = x - x_pad\n",
    "                avgpool = pooling(x)\n",
    "                result.insert(0, avgpool)\n",
    "        return torch.cat(result, dim=2)\n",
    "\n",
    "# Define the ResNet50-based Model\n",
    "class ft_net(nn.Module):\n",
    "\n",
    "    def __init__(self, class_num, droprate=0.5, stride=2, init_model=None, pool='avg'):\n",
    "        super(ft_net, self).__init__()\n",
    "        model_ft = models.resnet50(pretrained=True)\n",
    "        # avg pooling to global pooling\n",
    "        if stride == 1:\n",
    "            model_ft.layer4[0].downsample[0].stride = (1,1)\n",
    "            model_ft.layer4[0].conv2.stride = (1,1)\n",
    "\n",
    "        self.pool = pool\n",
    "        if pool =='avg+max':\n",
    "            model_ft.avgpool2 = nn.AdaptiveAvgPool2d((1,1))\n",
    "            model_ft.maxpool2 = nn.AdaptiveMaxPool2d((1,1))\n",
    "            self.model = model_ft\n",
    "            #self.classifier = ClassBlock(4096, class_num, droprate)\n",
    "        elif pool=='avg':\n",
    "            model_ft.avgpool2 = nn.AdaptiveAvgPool2d((1,1))\n",
    "            self.model = model_ft\n",
    "            #self.classifier = ClassBlock(2048, class_num, droprate)\n",
    "        elif pool=='max':\n",
    "            model_ft.maxpool2 = nn.AdaptiveMaxPool2d((1,1))\n",
    "            self.model = model_ft\n",
    "\n",
    "        if init_model!=None:\n",
    "            self.model = init_model.model\n",
    "            self.pool = init_model.pool\n",
    "            #self.classifier.add_block = init_model.classifier.add_block\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.conv1(x)\n",
    "        x = self.model.bn1(x)\n",
    "        x = self.model.relu(x)\n",
    "        x = self.model.maxpool(x)\n",
    "        x = self.model.layer1(x)\n",
    "        x = self.model.layer2(x)\n",
    "        x = self.model.layer3(x)\n",
    "        x = self.model.layer4(x)\n",
    "        # print(x.size())\n",
    "        if self.pool == 'avg+max':\n",
    "            x1 = self.model.avgpool2(x)\n",
    "            x2 = self.model.maxpool2(x)\n",
    "            x = torch.cat((x1,x2), dim = 1)\n",
    "            x = x.view(x.size(0), x.size(1))\n",
    "        elif self.pool == 'avg':\n",
    "            x = self.model.avgpool2(x)\n",
    "            x = x.view(x.size(0), x.size(1))\n",
    "        elif self.pool == 'max':\n",
    "            x = self.model.maxpool2(x)\n",
    "            x = x.view(x.size(0), x.size(1))\n",
    "        #x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Define the ResNet50-based part Model\n",
    "class ft_net_LPN(nn.Module):\n",
    "\n",
    "    def __init__(self, class_num, droprate=0.5, stride=2, init_model=None, pool='avg', block=6):\n",
    "        super(ft_net_LPN, self).__init__()\n",
    "        model_ft = models.resnet50(pretrained=True)\n",
    "        # avg pooling to global pooling\n",
    "        if stride == 1:\n",
    "            model_ft.layer4[0].downsample[0].stride = (1,1)\n",
    "            model_ft.layer4[0].conv2.stride = (1,1)\n",
    "\n",
    "        self.pool = pool\n",
    "        self.model = model_ft\n",
    "        self.block = block\n",
    "        if init_model!=None:\n",
    "            self.model = init_model.model\n",
    "            self.pool = init_model.pool\n",
    "            #self.classifier.add_block = init_model.classifier.add_block\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.conv1(x)\n",
    "        x = self.model.bn1(x)\n",
    "        x = self.model.relu(x)\n",
    "        x = self.model.maxpool(x)\n",
    "        x = self.model.layer1(x)\n",
    "        x = self.model.layer2(x)\n",
    "        x = self.model.layer3(x)\n",
    "        x = self.model.layer4(x)\n",
    "        # print(x.shape)\n",
    "        if self.pool == 'avg+max':\n",
    "            x1 = self.get_part_pool(x, pool='avg')\n",
    "            x2 = self.get_part_pool(x, pool='max')\n",
    "            x = torch.cat((x1,x2), dim = 1)\n",
    "            x = x.view(x.size(0), x.size(1), -1)\n",
    "        elif self.pool == 'avg':\n",
    "            x = self.get_part_pool(x)\n",
    "            x = x.view(x.size(0), x.size(1), -1)\n",
    "        elif self.pool == 'max':\n",
    "            x = self.get_part_pool(x, pool='max')\n",
    "            x = x.view(x.size(0), x.size(1), -1)\n",
    "        #x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def get_part_pool(self, x, pool='avg', no_overlap=True):\n",
    "        result = []\n",
    "        if pool == 'avg':\n",
    "            pooling = torch.nn.AdaptiveAvgPool2d((1,1))\n",
    "        elif pool == 'max':\n",
    "            pooling = torch.nn.AdaptiveMaxPool2d((1,1)) \n",
    "        H, W = x.size(2), x.size(3)\n",
    "        c_h, c_w = int(H/2), int(W/2)\n",
    "        per_h, per_w = H/(2*self.block),W/(2*self.block)\n",
    "        if per_h < 1 and per_w < 1:\n",
    "            new_H, new_W = H+(self.block-c_h)*2, W+(self.block-c_w)*2\n",
    "            x = nn.functional.interpolate(x, size=[new_H,new_W], mode='bilinear', align_corners=True)\n",
    "            H, W = x.size(2), x.size(3)\n",
    "            c_h, c_w = int(H/2), int(W/2)\n",
    "            per_h, per_w = H/(2*self.block),W/(2*self.block)\n",
    "        per_h, per_w = math.floor(per_h), math.floor(per_w)\n",
    "        for i in range(self.block):\n",
    "            i = i + 1\n",
    "            if i < self.block:\n",
    "                x_curr = x[:,:,(c_h-i*per_h):(c_h+i*per_h),(c_w-i*per_w):(c_w+i*per_w)]\n",
    "                if no_overlap and i > 1:\n",
    "                    x_pre = x[:,:,(c_h-(i-1)*per_h):(c_h+(i-1)*per_h),(c_w-(i-1)*per_w):(c_w+(i-1)*per_w)] \n",
    "                    x_pad = F.pad(x_pre,(per_h,per_h,per_w,per_w),\"constant\",0)\n",
    "                    x_curr = x_curr - x_pad\n",
    "                avgpool = pooling(x_curr)\n",
    "                result.append(avgpool)\n",
    "            else:\n",
    "                if no_overlap and i > 1:\n",
    "                    x_pre = x[:,:,(c_h-(i-1)*per_h):(c_h+(i-1)*per_h),(c_w-(i-1)*per_w):(c_w+(i-1)*per_w)]\n",
    "                    pad_h = c_h-(i-1)*per_h\n",
    "                    pad_w = c_w-(i-1)*per_w\n",
    "                    # x_pad = F.pad(x_pre,(pad_h,pad_h,pad_w,pad_w),\"constant\",0)\n",
    "                    if x_pre.size(2)+2*pad_h == H:\n",
    "                        x_pad = F.pad(x_pre,(pad_h,pad_h,pad_w,pad_w),\"constant\",0)\n",
    "                    else:\n",
    "                        ep = H - (x_pre.size(2)+2*pad_h)\n",
    "                        x_pad = F.pad(x_pre,(pad_h+ep,pad_h,pad_w+ep,pad_w),\"constant\",0)\n",
    "                    x = x - x_pad\n",
    "                avgpool = pooling(x)\n",
    "                result.append(avgpool)\n",
    "        return torch.cat(result, dim=2)\n",
    "\n",
    "# For cvusa/cvact\n",
    "class two_view_net(nn.Module):\n",
    "    def __init__(self, class_num, droprate, stride = 1, pool = 'avg', share_weight = False, VGG16=False, LPN=False, block=2):\n",
    "        super(two_view_net, self).__init__()\n",
    "        self.LPN = LPN\n",
    "        self.block = block\n",
    "        self.sqr = True # if the satellite image is square ring partition and the ground image is row partition, self.sqr is True. Otherwise it is False.\n",
    "        if VGG16:\n",
    "            if LPN:\n",
    "                # satelite\n",
    "                self.model_1 = ft_net_VGG16_LPN(class_num, stride=stride, pool=pool, block = block)\n",
    "                if self.sqr:\n",
    "                    self.model_1 = ft_net_VGG16_LPN_R(class_num, stride=stride, pool=pool, block=block)\n",
    "            else:\n",
    "                self.model_1 =  ft_net_VGG16(class_num, stride=stride, pool = pool)\n",
    "                # self.vgg1 = models.vgg16_bn(pretrained=True)\n",
    "                # self.model_1 = SAFA()\n",
    "                # self.model_1 = SAFA_FC(64, 32, 8)\n",
    "        else:\n",
    "            #resnet50 LPN cvusa/cvact\n",
    "            self.model_1 =  ft_net_cvusa_LPN(class_num, stride=stride, pool = pool, block=block)\n",
    "            if self.sqr:\n",
    "                self.model_1 = ft_net_cvusa_LPN_R(class_num, stride=stride, pool=pool, block=block)\n",
    "            self.block = self.model_1.block\n",
    "        if share_weight:\n",
    "            self.model_2 = self.model_1\n",
    "        else:\n",
    "            if VGG16:\n",
    "                if LPN:\n",
    "                    #street\n",
    "                    self.model_2 = ft_net_VGG16_LPN(class_num, stride=stride, pool=pool, block = block, row = self.sqr)\n",
    "                else:\n",
    "                    self.model_2 =  ft_net_VGG16(class_num, stride = stride, pool = pool)\n",
    "                    # self.vgg2 = models.vgg16_bn(pretrained=True)\n",
    "                    # self.model_2 = SAFA()\n",
    "                    # self.model_2 = SAFA_FC(64, 32, 8)\n",
    "            else:\n",
    "                self.model_2 =  ft_net_cvusa_LPN(class_num, stride = stride, pool = pool, block=block, row = self.sqr)\n",
    "        if LPN:\n",
    "            if VGG16:\n",
    "                if pool == 'avg+max':\n",
    "                    for i in range(self.block):\n",
    "                        name = 'classifier'+str(i)\n",
    "                        setattr(self, name, ClassBlock(1024, class_num, droprate))\n",
    "                else:\n",
    "                    for i in range(self.block):\n",
    "                        name = 'classifier'+str(i)\n",
    "                        setattr(self, name, ClassBlock(512, class_num, droprate))\n",
    "            else:\n",
    "                if pool == 'avg+max':\n",
    "                    for i in range(self.block):\n",
    "                        name = 'classifier'+str(i)\n",
    "                        setattr(self, name, ClassBlock(4096, class_num, droprate))\n",
    "                else:\n",
    "                    for i in range(self.block):\n",
    "                        name = 'classifier'+str(i)\n",
    "                        setattr(self, name, ClassBlock(2048, class_num, droprate))\n",
    "        else:    \n",
    "            self.classifier = ClassBlock(2048, class_num, droprate)\n",
    "            if pool =='avg+max':\n",
    "                self.classifier = ClassBlock(4096, class_num, droprate)\n",
    "            if VGG16:\n",
    "                self.classifier = ClassBlock(512, class_num, droprate)\n",
    "                # self.classifier = ClassBlock(4096, class_num, droprate, num_bottleneck=512) #safa 情况下\n",
    "                if pool =='avg+max':\n",
    "                    self.classifier = ClassBlock(1024, class_num, droprate)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        if self.LPN:\n",
    "            if x1 is None:\n",
    "                y1 = None\n",
    "            else:\n",
    "                x1 = self.model_1(x1)\n",
    "                y1 = self.part_classifier(x1)\n",
    "\n",
    "            if x2 is None:\n",
    "                y2 = None\n",
    "            else:\n",
    "                x2 = self.model_2(x2)\n",
    "                y2 = self.part_classifier(x2)\n",
    "        else:\n",
    "            if x1 is None:\n",
    "                y1 = None\n",
    "            else:\n",
    "                # x1 = self.vgg1.features(x1)\n",
    "                x1 = self.model_1(x1)\n",
    "                y1 = self.classifier(x1)\n",
    "\n",
    "            if x2 is None:\n",
    "                y2 = None\n",
    "            else:\n",
    "                # x2 = self.vgg2.features(x2)\n",
    "                x2 = self.model_2(x2)\n",
    "                y2 = self.classifier(x2)\n",
    "        return y1, y2\n",
    "\n",
    "    def part_classifier(self, x):\n",
    "        part = {}\n",
    "        predict = {}\n",
    "        for i in range(self.block):\n",
    "            # part[i] = torch.squeeze(x[:,:,i])\n",
    "            part[i] = x[:,:,i].view(x.size(0),-1)\n",
    "            name = 'classifier'+str(i)\n",
    "            c = getattr(self, name)\n",
    "            predict[i] = c(part[i])\n",
    "        y = []\n",
    "        for i in range(self.block):\n",
    "            y.append(predict[i])\n",
    "        if not self.training:\n",
    "            return torch.stack(y, dim=2)\n",
    "        return y\n",
    "\n",
    "class three_view_net(nn.Module):\n",
    "    def __init__(self, class_num, droprate, stride = 2, pool = 'avg', share_weight = False, VGG16=False, LPN=False, block=6):\n",
    "        super(three_view_net, self).__init__()\n",
    "        self.LPN = LPN\n",
    "        self.block = block\n",
    "        if VGG16:\n",
    "            self.model_1 =  ft_net_VGG16(class_num, stride = stride, pool = pool)\n",
    "            self.model_2 =  ft_net_VGG16(class_num, stride = stride, pool = pool)\n",
    "        elif LPN:\n",
    "            self.model_1 =  ft_net_LPN(class_num, stride = stride, pool = pool, block = block)\n",
    "            self.model_2 =  ft_net_LPN(class_num, stride = stride, pool = pool, block = block)\n",
    "            # self.block = self.model_1.block\n",
    "        else: \n",
    "            self.model_1 =  ft_net(class_num, stride = stride, pool = pool)\n",
    "            self.model_2 =  ft_net(class_num, stride = stride, pool = pool)\n",
    "\n",
    "        if share_weight:\n",
    "            self.model_3 = self.model_1\n",
    "        else:\n",
    "            if VGG16:\n",
    "                self.model_3 =  ft_net_VGG16(class_num, stride = stride, pool = pool)\n",
    "            elif LPN:\n",
    "                self.model_3 =  ft_net_LPN(class_num, stride = stride, pool = pool, block = block)\n",
    "            else:\n",
    "                self.model_3 =  ft_net(class_num, stride = stride, pool = pool)\n",
    "        if LPN:\n",
    "            if pool == 'avg+max':\n",
    "                for i in range(self.block):\n",
    "                    name = 'classifier'+str(i)\n",
    "                    setattr(self, name, ClassBlock(4096, class_num, droprate))\n",
    "            else:\n",
    "                for i in range(self.block):\n",
    "                    name = 'classifier'+str(i)\n",
    "                    setattr(self, name, ClassBlock(2048, class_num, droprate))\n",
    "        else:    \n",
    "            self.classifier = ClassBlock(2048, class_num, droprate)\n",
    "            if pool =='avg+max':\n",
    "                self.classifier = ClassBlock(4096, class_num, droprate)\n",
    "\n",
    "    def forward(self, x1, x2, x3, x4 = None): # x4 is extra data\n",
    "        if self.LPN:\n",
    "            if x1 is None:\n",
    "                y1 = None\n",
    "            else:\n",
    "                x1 = self.model_1(x1)\n",
    "                y1 = self.part_classifier(x1)\n",
    "\n",
    "            if x2 is None:\n",
    "                y2 = None\n",
    "            else:\n",
    "                x2 = self.model_2(x2)\n",
    "                y2 = self.part_classifier(x2)\n",
    "\n",
    "            if x3 is None:\n",
    "                y3 = None\n",
    "            else:\n",
    "                x3 = self.model_3(x3)\n",
    "                y3 = self.part_classifier(x3)\n",
    "\n",
    "            if x4 is None:\n",
    "                return y1, y2, y3\n",
    "            else:\n",
    "                x4 = self.model_2(x4)\n",
    "                y4 = self.part_classifier(x4)\n",
    "                return y1, y2, y3, y4\n",
    "        else:\n",
    "            if x1 is None:\n",
    "                y1 = None\n",
    "            else:\n",
    "                x1 = self.model_1(x1)\n",
    "                y1 = self.classifier(x1)\n",
    "\n",
    "            if x2 is None:\n",
    "                y2 = None\n",
    "            else:\n",
    "                x2 = self.model_2(x2)\n",
    "                y2 = self.classifier(x2)\n",
    "\n",
    "            if x3 is None:\n",
    "                y3 = None\n",
    "            else:\n",
    "                x3 = self.model_3(x3)\n",
    "                y3 = self.classifier(x3)\n",
    "\n",
    "            if x4 is None:\n",
    "                return y1, y2, y3\n",
    "            else:\n",
    "                x4 = self.model_2(x4)\n",
    "                y4 = self.classifier(x4)\n",
    "                return y1, y2, y3, y4\n",
    "\n",
    "    def part_classifier(self, x):\n",
    "        part = {}\n",
    "        predict = {}\n",
    "        for i in range(self.block):\n",
    "            part[i] = x[:,:,i].view(x.size(0),-1)\n",
    "            # part[i] = torch.squeeze(x[:,:,i])\n",
    "            name = 'classifier'+str(i)\n",
    "            c = getattr(self, name)\n",
    "            predict[i] = c(part[i])\n",
    "        y = []\n",
    "        for i in range(self.block):\n",
    "            y.append(predict[i])\n",
    "        if not self.training:\n",
    "            return torch.stack(y, dim=2)\n",
    "        return y\n",
    "\n",
    "\n",
    "'''\n",
    "# debug model structure\n",
    "# Run this code with:\n",
    "python model.py\n",
    "'''\n",
    "if __name__ == '__main__':\n",
    "# Here I left a simple forward function.\n",
    "# Test the model, before you train it. \n",
    "    net = two_view_net(701, droprate=0.5, pool='avg', stride=1, VGG16=False, LPN=True, block=8)\n",
    "\n",
    "    # net = three_view_net(701, droprate=0.5, pool='avg', stride=1, share_weight=True, LPN=True, block=2)\n",
    "    # net.eval()\n",
    "\n",
    "    # net = ft_net_VGG16_LPN_R(701)\n",
    "    # net = ft_net_cvusa_LPN(701, stride=1)\n",
    "    # net = ft_net(701)\n",
    "\n",
    "    print(net)\n",
    "\n",
    "    input = Variable(torch.FloatTensor(2, 3, 256, 256))\n",
    "    output1,output2 = net(input,input)\n",
    "    # output1,output2,output3 = net(input,input,input)\n",
    "    # output1 = net(input)\n",
    "    # print('net output size:')\n",
    "    # print(output1.shape)\n",
    "    # print(output.shape)\n",
    "    for i in range(len(output1)):\n",
    "        print(output1[i].shape)\n",
    "    # x = torch.randn(2,512,8,8)\n",
    "    # x_shape = x.shape\n",
    "    # pool = AzimuthPool2d(x_shape, 8)\n",
    "    # out = pool(x)\n",
    "    # print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 8, 1])\n"
     ]
    }
   ],
   "source": [
    "def get_part_pool(x, pool='avg', no_overlap=True):\n",
    "        block = 8\n",
    "        result = []\n",
    "        if pool == 'avg':\n",
    "            pooling = torch.nn.AdaptiveAvgPool2d((1,1))\n",
    "        elif pool == 'max':\n",
    "            pooling = torch.nn.AdaptiveMaxPool2d((1,1)) \n",
    "        H, W = x.size(2), x.size(3)\n",
    "        c_h, c_w = int(H/2), int(W/2)\n",
    "        per_h, per_w = H/(2*block),W/(2*block)\n",
    "        if per_h < 1 and per_w < 1:\n",
    "            new_H, new_W = H+(block-c_h)*2, W+(block-c_w)*2\n",
    "            x = nn.functional.interpolate(x, size=[new_H,new_W], mode='bilinear')\n",
    "            H, W = x.size(2), x.size(3)\n",
    "            c_h, c_w = int(H/2), int(W/2)\n",
    "            per_h, per_w = H/(2*block),W/(2*block)\n",
    "        per_h, per_w = math.floor(per_h), math.floor(per_w)\n",
    "        for i in range(block):\n",
    "            i = i + 1\n",
    "            if i < block:\n",
    "                x_curr = x[:,:,(c_h-i*per_h):(c_h+i*per_h),(c_w-i*per_w):(c_w+i*per_w)]\n",
    "                if no_overlap and i > 1:\n",
    "                    x_pre = x[:,:,(c_h-(i-1)*per_h):(c_h+(i-1)*per_h),(c_w-(i-1)*per_w):(c_w+(i-1)*per_w)] \n",
    "                    x_pad = F.pad(x_pre,(per_h,per_h,per_w,per_w),\"constant\",0)\n",
    "                    x_curr = x_curr - x_pad\n",
    "                avgpool = pooling(x_curr)\n",
    "                result.insert(0, avgpool)\n",
    "            else:\n",
    "                if no_overlap and i > 1:\n",
    "                    x_pre = x[:,:,(c_h-(i-1)*per_h):(c_h+(i-1)*per_h),(c_w-(i-1)*per_w):(c_w+(i-1)*per_w)]\n",
    "                    pad_h = c_h-(i-1)*per_h\n",
    "                    pad_w = c_w-(i-1)*per_w\n",
    "                    # x_pad = F.pad(x_pre,(pad_h,pad_h,pad_w,pad_w),\"constant\",0)\n",
    "                    if x_pre.size(2)+2*pad_h == H:\n",
    "                        x_pad = F.pad(x_pre,(pad_h,pad_h,pad_w,pad_w),\"constant\",0)\n",
    "                    else:\n",
    "                        ep = H - (x_pre.size(2)+2*pad_h)\n",
    "                        x_pad = F.pad(x_pre,(pad_h+ep,pad_h,pad_w+ep,pad_w),\"constant\",0)\n",
    "                    x = x - x_pad\n",
    "                avgpool = pooling(x)\n",
    "                result.insert(0, avgpool)\n",
    "        return torch.cat(result, dim=2)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    x = torch.rand(1, 3, 256, 256)\n",
    "    out = get_part_pool(x)\n",
    "    print(out.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MSConv(nn.Module):\n",
    "    def __init__(self, inplans, outplans):\n",
    "        super(MSConv, self).__init__()\n",
    "        self.conv3 = nn.Conv2d(inplans, outplans, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(inplans, outplans, kernel_size=5, stride=1, padding=1)\n",
    "        self.conv7 = nn.Conv2d(inplans, outplans, kernel_size=7, stride=1, padding=1)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out1 = self.conv3(x)\n",
    "        out2 = self.conv5(x)\n",
    "        out3 = self.conv7(x)\n",
    "        part7 = out1[:, :, 1:6, 1:6]\n",
    "        part5 = out2[:, :, 1:4, 1:4]\n",
    "\n",
    "        out3 = out3 + part5\n",
    "        out2 = out2 + part7\n",
    "\n",
    "        part5_2 = out2[:, :, 1:4, 1:4]\n",
    "        out3 = out3 + part5_2\n",
    "\n",
    "        out3 = F.interpolate(out3, (5, 5))\n",
    "        out2 = out2 + out3\n",
    "        out2 = F.interpolate(out2, (7, 7))\n",
    "        out3 = F.interpolate(out3, (7, 7))\n",
    "        out = out1 + out2 + out3\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "        # out = torch.sigmoid(torch.add(identity, F.interpolate(self.k2(x), identity.size()[2:]))) # sigmoid(identity + k2)\n",
    "        # out = torch.mul(self.k3(x), out) # k3 * sigmoid(identity + k2)\n",
    "        # out = self.k4(out) # k4\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    x = torch.rand(1, 256, 7, 7)\n",
    "    net = MSConv(256, 256)\n",
    "    out = net(x)\n",
    "    print(out.shape)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4d80541b0b515a3e45ee7a1ccc48716ea2070627a1ff6669ac05393be4e62eb"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('myenv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
